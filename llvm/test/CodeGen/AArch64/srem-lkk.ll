; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=aarch64-unknown-linux-gnu < %s | FileCheck %s

define i32 @lower_srem_positive_odd(i32 %x) {
; CHECK-LABEL: lower_srem_positive_odd:
; CHECK:       // %bb.0:
; CHECK-NEXT:    mov x10, #7589
; CHECK-NEXT:    movk x10, #4139, lsl #16
; CHECK-NEXT:    movk x10, #55878, lsl #32
; CHECK-NEXT:    // kill: def $w0 killed $w0 def $x0
; CHECK-NEXT:    sxtw x9, w0
; CHECK-NEXT:    movk x10, #689, lsl #48
; CHECK-NEXT:    mov w8, #94
; CHECK-NEXT:    mul x9, x9, x10
; CHECK-NEXT:    mov w10, #95
; CHECK-NEXT:    and w8, w8, w0, asr #31
; CHECK-NEXT:    umulh x9, x9, x10
; CHECK-NEXT:    sub w0, w9, w8
; CHECK-NEXT:    ret
  %1 = srem i32 %x, 95
  ret i32 %1
}


define i32 @lower_srem_positive_even(i32 %x) {
; CHECK-LABEL: lower_srem_positive_even:
; CHECK:       // %bb.0:
; CHECK-NEXT:    mov x10, #7172
; CHECK-NEXT:    movk x10, #61579, lsl #16
; CHECK-NEXT:    movk x10, #54159, lsl #32
; CHECK-NEXT:    // kill: def $w0 killed $w0 def $x0
; CHECK-NEXT:    sxtw x9, w0
; CHECK-NEXT:    movk x10, #61, lsl #48
; CHECK-NEXT:    mov w8, #1059
; CHECK-NEXT:    mul x9, x9, x10
; CHECK-NEXT:    mov w10, #1060
; CHECK-NEXT:    and w8, w8, w0, asr #31
; CHECK-NEXT:    umulh x9, x9, x10
; CHECK-NEXT:    sub w0, w9, w8
; CHECK-NEXT:    ret
  %1 = srem i32 %x, 1060
  ret i32 %1
}


define i32 @lower_srem_negative_odd(i32 %x) {
; CHECK-LABEL: lower_srem_negative_odd:
; CHECK:       // %bb.0:
; CHECK-NEXT:    mov x10, #91
; CHECK-NEXT:    movk x10, #23205, lsl #16
; CHECK-NEXT:    movk x10, #42240, lsl #32
; CHECK-NEXT:    // kill: def $w0 killed $w0 def $x0
; CHECK-NEXT:    sxtw x9, w0
; CHECK-NEXT:    movk x10, #90, lsl #48
; CHECK-NEXT:    mov w8, #722
; CHECK-NEXT:    mul x9, x9, x10
; CHECK-NEXT:    mov w10, #723
; CHECK-NEXT:    and w8, w8, w0, asr #31
; CHECK-NEXT:    umulh x9, x9, x10
; CHECK-NEXT:    sub w0, w9, w8
; CHECK-NEXT:    ret
  %1 = srem i32 %x, -723
  ret i32 %1
}


define i32 @lower_srem_negative_even(i32 %x) {
; CHECK-LABEL: lower_srem_negative_even:
; CHECK:       // %bb.0:
; CHECK-NEXT:    mov x10, #21004
; CHECK-NEXT:    movk x10, #6399, lsl #16
; CHECK-NEXT:    movk x10, #55820, lsl #32
; CHECK-NEXT:    // kill: def $w0 killed $w0 def $x0
; CHECK-NEXT:    sxtw x9, w0
; CHECK-NEXT:    movk x10, #2, lsl #48
; CHECK-NEXT:    mov w8, #22980
; CHECK-NEXT:    mul x9, x9, x10
; CHECK-NEXT:    mov w10, #22981
; CHECK-NEXT:    and w8, w8, w0, asr #31
; CHECK-NEXT:    umulh x9, x9, x10
; CHECK-NEXT:    sub w0, w9, w8
; CHECK-NEXT:    ret
  %1 = srem i32 %x, -22981
  ret i32 %1
}


; Don't lower if we can combine srem with sdiv.
define i32 @combine_srem_sdiv(i32 %x) {
; CHECK-LABEL: combine_srem_sdiv:
; CHECK:       // %bb.0:
; CHECK-NEXT:    mov w8, #37253
; CHECK-NEXT:    movk w8, #44150, lsl #16
; CHECK-NEXT:    smull x8, w0, w8
; CHECK-NEXT:    lsr x8, x8, #32
; CHECK-NEXT:    add w8, w8, w0
; CHECK-NEXT:    asr w9, w8, #6
; CHECK-NEXT:    add w8, w9, w8, lsr #31
; CHECK-NEXT:    mov w9, #95
; CHECK-NEXT:    msub w9, w8, w9, w0
; CHECK-NEXT:    add w0, w9, w8
; CHECK-NEXT:    ret
  %1 = srem i32 %x, 95
  %2 = sdiv i32 %x, 95
  %3 = add i32 %1, %2
  ret i32 %3
}

; Don't lower for divisors that are a power of two.
define i32 @dont_lower_srem_power_of_two(i32 %x) {
; CHECK-LABEL: dont_lower_srem_power_of_two:
; CHECK:       // %bb.0:
; CHECK-NEXT:    add w8, w0, #63 // =63
; CHECK-NEXT:    cmp w0, #0 // =0
; CHECK-NEXT:    csel w8, w8, w0, lt
; CHECK-NEXT:    and w8, w8, #0xffffffc0
; CHECK-NEXT:    sub w0, w0, w8
; CHECK-NEXT:    ret
  %1 = srem i32 %x, 64
  ret i32 %1
}

; Don't lower if the divisor is one.
define i32 @dont_lower_srem_one(i32 %x) {
; CHECK-LABEL: dont_lower_srem_one:
; CHECK:       // %bb.0:
; CHECK-NEXT:    mov w0, wzr
; CHECK-NEXT:    ret
  %1 = srem i32 %x, 1
  ret i32 %1
}

; Don't lower if the divisor is 2^31.
define i32 @dont_lower_srem_i32_smax(i32 %x) {
; CHECK-LABEL: dont_lower_srem_i32_smax:
; CHECK:       // %bb.0:
; CHECK-NEXT:    mov w8, #2147483647
; CHECK-NEXT:    add w8, w0, w8
; CHECK-NEXT:    cmp w0, #0 // =0
; CHECK-NEXT:    csel w8, w8, w0, lt
; CHECK-NEXT:    and w8, w8, #0x80000000
; CHECK-NEXT:    add w0, w0, w8
; CHECK-NEXT:    ret
  %1 = srem i32 %x, 2147483648
  ret i32 %1
}

; Don't lower i64 srem
define i64 @dont_lower_srem_i64(i64 %x) {
; CHECK-LABEL: dont_lower_srem_i64:
; CHECK:       // %bb.0:
; CHECK-NEXT:    mov x8, #58849
; CHECK-NEXT:    movk x8, #48148, lsl #16
; CHECK-NEXT:    movk x8, #33436, lsl #32
; CHECK-NEXT:    movk x8, #21399, lsl #48
; CHECK-NEXT:    smulh x8, x0, x8
; CHECK-NEXT:    asr x9, x8, #5
; CHECK-NEXT:    add x8, x9, x8, lsr #63
; CHECK-NEXT:    mov w9, #98
; CHECK-NEXT:    msub x0, x8, x9, x0
; CHECK-NEXT:    ret
  %1 = srem i64 %x, 98
  ret i64 %1
}

@.str = private unnamed_addr constant [4 x i8] c"%d\0A\00", align 1

declare dso_local i32 @printf(i8* nocapture readonly, ...) local_unnamed_addr #1

define void @srem_loop(i32 %x) {
; CHECK-LABEL: srem_loop:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    str x30, [sp, #-64]! // 8-byte Folded Spill
; CHECK-NEXT:    stp x24, x23, [sp, #16] // 16-byte Folded Spill
; CHECK-NEXT:    stp x22, x21, [sp, #32] // 16-byte Folded Spill
; CHECK-NEXT:    stp x20, x19, [sp, #48] // 16-byte Folded Spill
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    .cfi_offset w19, -8
; CHECK-NEXT:    .cfi_offset w20, -16
; CHECK-NEXT:    .cfi_offset w21, -24
; CHECK-NEXT:    .cfi_offset w22, -32
; CHECK-NEXT:    .cfi_offset w23, -40
; CHECK-NEXT:    .cfi_offset w24, -48
; CHECK-NEXT:    .cfi_offset w30, -64
; CHECK-NEXT:    mov x23, #7589
; CHECK-NEXT:    movk x23, #4139, lsl #16
; CHECK-NEXT:    movk x23, #55878, lsl #32
; CHECK-NEXT:    adrp x21, .L.str
; CHECK-NEXT:    mov w19, w0
; CHECK-NEXT:    mov w20, wzr
; CHECK-NEXT:    mov w0, #1
; CHECK-NEXT:    mov w22, #94
; CHECK-NEXT:    movk x23, #689, lsl #48
; CHECK-NEXT:    mov w24, #95
; CHECK-NEXT:    add x21, x21, :lo12:.L.str
; CHECK-NEXT:  .LBB9_1: // %loop
; CHECK-NEXT:    // =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    sxtw x9, w0
; CHECK-NEXT:    mul x9, x9, x23
; CHECK-NEXT:    and w8, w22, w0, asr #31
; CHECK-NEXT:    umulh x9, x9, x24
; CHECK-NEXT:    sub w8, w9, w8
; CHECK-NEXT:    add w20, w8, w20
; CHECK-NEXT:    mov x0, x21
; CHECK-NEXT:    mov w1, w20
; CHECK-NEXT:    bl printf
; CHECK-NEXT:    // kill: def $w0 killed $w0 def $x0
; CHECK-NEXT:    cmp w0, w19
; CHECK-NEXT:    b.lo .LBB9_1
; CHECK-NEXT:  // %bb.2: // %afterloop
; CHECK-NEXT:    ldp x20, x19, [sp, #48] // 16-byte Folded Reload
; CHECK-NEXT:    ldp x22, x21, [sp, #32] // 16-byte Folded Reload
; CHECK-NEXT:    ldp x24, x23, [sp, #16] // 16-byte Folded Reload
; CHECK-NEXT:    ldr x30, [sp], #64 // 8-byte Folded Reload
; CHECK-NEXT:    ret
entry:
  %0 = add i32 0, 0
  br label %loop
loop:
  %1 = phi i32 [ 1, %entry ], [ %5, %loop ]
  %2 = phi i32 [%0, %entry], [%4, %loop]
  %3 = srem i32 %1, 95
  %4 = add i32 %3, %2
  %5 = tail call i32 (i8*, ...) @printf(i8* nonnull dereferenceable(1) getelementptr inbounds ([4 x i8], [4 x i8]* @.str, i64 0, i64 0), i32 %4)
  %6 = icmp ult i32 %5, %x
  br i1 %6, label %loop, label %afterloop

afterloop:
  ret void
}
